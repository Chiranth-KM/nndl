import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.datasets import mnist
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

(x_train,_),(x_test,_)=mnist.load_data()
x_train=x_train.astype('float32')/255.0
x_test=x_test.astype('float32')/255.0

x_train=x_train.reshape(-1,28*28)
x_test=x_test.reshape(-1,28*28)

def build_model(input_dim,encoding_dim):
    input_layer=Input(shape=(input_dim,))
    encoded=Dense(encoding_dim[0],activation='relu')(input_layer)
    for units in encoding_dim[1:]:
        encoded=Dense(units,activation='relu')(encoded)

    decoded_layer=encoding_dim[::-1]
    decoded=Dense(decoded_layer[0],activation='relu')(encoded)
    for units in encoding_dim[1:-1]:
        decoded=Dense(units,activation='relu')(decoded)
    op_layer=Dense(input_dim,activation='sigmoid')(decoded)

    autoencoder=Model(input_layer, op_layer)
    encoder=Model(input_layer, encoded)
    return autoencoder, encoder

encoding_dim=[64,32,16]
autoencoder,encoder=build_model(input_dim=784, encoding_dim=encoding_dim)
autoencoder.compile(optimizer=Adam(learning_rate=0.001),loss='mse')
history=autoencoder.fit(x_train,x_train, epochs=20, batch_size=256, validation_data=(x_test,x_test))

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title("Loss vs Epochs")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.show()

reconstructed=autoencoder.predict(x_test)

n=10
plt.figure(figsize=(20,4))
for i in range(n):
    ax=plt.subplot(2,n,i+1)
    plt.imshow(x_test[i].reshape(28,28),cmap='gray')
    plt.title("orginal")
    plt.axis("off")

    ax=plt.subplot(2,n,i+1+n)
    plt.imshow(reconstructed[i].reshape(28,28), cmap='gray')
    plt.title("reconstructed")
    plt.axis("off")
plt.show()
